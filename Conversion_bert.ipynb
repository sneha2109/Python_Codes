{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dda8781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download requirements\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3862d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt for file name to convert to csv\n",
    "my_file = input(\"File to convert to csv:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert file to csv\n",
    "base = os.path.splitext(my_file)[0]\n",
    "new_name = base + '.csv'\n",
    "os.rename(my_file, new_name)\n",
    "#print(base + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2725e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read converted file into dataframe\n",
    "df = pd.read_csv(new_name)\n",
    "#df1 = pd.read_csv(\"mtsamples_original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f458a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare two csv files\n",
    "df1 = pd.read_csv(\"cities.csv\")\n",
    "df_1 = pd.DataFrame(df)\n",
    "df_2 = pd.DataFrame(df1)\n",
    "#df_1.eq(df_2)\n",
    "#if schemas match, do nothing.  If they do not, prompt for whether or not to merge the two dataframes\n",
    "if df_1.equals(df_2) == True:\n",
    "    print(\"Columns match\")\n",
    "else:\n",
    "    my_response = input(\"Schemas are not the same. Would you like to convert the file to appropriate format?:\")\n",
    "    if (my_response == \"Yes\"):\n",
    "        df3 = pd.concat([df_1,df_2]).drop_duplicates(keep=False)\n",
    "    #df3 = df_1.merge(df_2, how = 'inner', indicator=False)\n",
    "        print(df3)\n",
    "    else:\n",
    "        print(\"No changes made\")\n",
    "\n",
    "#print(df_1.compare(df_2))\n",
    "#print(df_1 == df_2)\n",
    "#df_2.reset_index(drop=True, inplace=True)\n",
    "#if df_1 == df_2:\n",
    " #   print(\"true\")\n",
    "#else:\n",
    " #   print(\"false\")\n",
    "#print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store database file as dataframe and look at schema\n",
    "import sqlite3\n",
    "con = sqlite3.connect('NoteStore.sqlite')\n",
    "df3 = pd.read_sql_query('select * from sqlite_master', con)\n",
    "df_1 = pd.DataFrame(df3)\n",
    "pd.io.json.build_table_schema(df_1)\n",
    "#print(df_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109ce1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare 2 different schemas - one database and one csv\n",
    "# store database file as dataframe \n",
    "import sqlite3\n",
    "con = sqlite3.connect('NoteStore.sqlite')\n",
    "df3 = pd.read_sql_query('select * from sqlite_master', con)\n",
    "df_1 = pd.DataFrame(df3)\n",
    "pd.io.json.build_table_schema(df_1)\n",
    "\n",
    "# store csv file as dataframe\n",
    "df2 = pd.read_csv(\"cities.csv\")\n",
    "df_2 = pd.DataFrame(df2)\n",
    "pd.io.json.build_table_schema(df_2)\n",
    "\n",
    "# combine the two dataframes - option if prompts will not be needed\n",
    "df3 = pd.concat([df_1,df_2],axis=0, ignore_index=True)\n",
    "pd.io.json.build_table_schema(df3)\n",
    "#print(df_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at 2 schemas\n",
    "#df1 = pd.read_csv(\"cities.csv\")\n",
    "#df_1 = pd.DataFrame(df1)\n",
    "#pd.io.json.build_table_schema(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = pd.read_csv(\"mtsamples.csv\")\n",
    "#df_2 = pd.DataFrame(df2)\n",
    "#pd.io.json.build_table_schema(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d70a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two similar dataframes - csv - into one dataframe\n",
    "df1 = pd.read_csv(\"cities.csv\")\n",
    "df_1 = pd.DataFrame(df1)\n",
    "pd.io.json.build_table_schema(df_1)\n",
    "df2 = pd.read_csv(\"mtsamples.csv\")\n",
    "df_2 = pd.DataFrame(df2)\n",
    "pd.io.json.build_table_schema(df_2)\n",
    "#df3 = pd.concat([df_1,df_2]).drop_duplicates(keep=False)\n",
    "df3 = pd.concat([df_1,df_2],axis=0, ignore_index=True)\n",
    "pd.io.json.build_table_schema(df3)\n",
    "#print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert json file into csv\n",
    "# convert json file into dataframe\n",
    "pdObj = pd.read_json('movies.json', orient='index')\n",
    "\n",
    "# convert dataframe to csv \n",
    "csvData = pdObj.to_csv('streaming.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare one dataframe to another\n",
    "#df1 = pd.read_csv(\"cities.csv\")\n",
    "#df_1 = pd.DataFrame(df)\n",
    "#df_2 = pd.DataFrame(df1)\n",
    "#df_1.eq(df_2)\n",
    "#if df_1.equals(df_2) == True:\n",
    " #   print(\"Columns match\")\n",
    "#else:\n",
    " #   my_response = input(\"Schemas are not the same. Would you like to convert for file to appropriate format?:\")\n",
    "  #  if (my_response == \"Yes\"):\n",
    "  #      df3 = pd.concat([df_1,df_2]).drop_duplicates(keep=False)\n",
    "    #df3 = df_1.merge(df_2, how = 'inner', indicator=False)\n",
    "  #      print(df3)\n",
    "  #  else:\n",
    "  #      print(\"No changes made\")\n",
    "\n",
    "#print(df_1.compare(df_2))\n",
    "#print(df_1 == df_2)\n",
    "#df_2.reset_index(drop=True, inplace=True)\n",
    "#if df_1 == df_2:\n",
    " #   print(\"true\")\n",
    "#else:\n",
    " #   print(\"false\")\n",
    "#print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9941cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install data model\n",
    "!pip install simpletransformers --use-feature=2020-resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df3[['transcription', 'medical_specialty']]\n",
    "data = data.drop(data[data['transcription'].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4180e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc0854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from stop_words import get_stop_words\n",
    "import string\n",
    "\n",
    "def clean_text(text): \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    newtext = ''.join([w for w in text if not w.isdigit()]) \n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    newtext = newtext.lower()\n",
    "    newtext = REPLACE_BY_SPACE_RE.sub('', newtext)\n",
    "    STOPWORDS = set(get_stop_words('en'))\n",
    "    words = newtext.split(\" \")\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        if words[i] in STOPWORDS:\n",
    "            words.pop(i)\n",
    "        else:\n",
    "            i += 1\n",
    "    newtext = ' '.join(map(str, words))\n",
    "    return newtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57efa9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data['medical_specialty'].value_counts()\n",
    "others = [k for k,v in counts.items() if v<100]\n",
    "for each_spec in others:\n",
    "    data.loc[data['medical_specialty']==each_spec, 'medical_specialty'] = 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db847d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "data = data.rename(index = str, columns = {'transcription': 'text'})\n",
    "data.loc[:, 'text'] = [clean_text(x) for x in data['text'].values]\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(data['medical_specialty'])\n",
    "\n",
    "data.loc[:, 'class_label'] = le.transform(data['medical_specialty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e38916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    bal_acc = balanced_accuracy_score(actual,pred)\n",
    "    f1_sc = f1_score(actual,pred,average=\"micro\")\n",
    "    return bal_acc, f1_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30428c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cuda_available = torch.cuda.is_available()\n",
    "learning_rate = 1e-5\n",
    "num_of_epochs = 3\n",
    "num_classes = len(data[\"class_label\"].unique())\n",
    "class_weights = [1]*num_classes\n",
    "model_args = ClassificationArgs(num_train_epochs=num_of_epochs,learning_rate = learning_rate,  reprocess_input_data= True, save_model_every_epoch=False, overwrite_output_dir= True)\n",
    "model = ClassificationModel(\n",
    "    \"roberta\",\n",
    "    \"roberta-base\",\n",
    "    num_labels=num_classes,\n",
    "    weight=class_weights,\n",
    "    use_cuda=cuda_available,\n",
    "    args=model_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dae450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_bert = data[\"text\"]\n",
    "Y_bert = data[\"class_label\"]\n",
    "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(X_bert, Y_bert, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(columns=['text','labels'])\n",
    "train_df['text'] = X_train_bert\n",
    "train_df['labels'] = y_train_bert\n",
    "test_df = pd.DataFrame(columns=['text','labels'])\n",
    "test_df['text'] = X_test_bert\n",
    "test_df['labels'] = y_test_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99071eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model(train_df)\n",
    "model.save_model()\n",
    "result, model_outputs, wrong_predictions = model.eval_model(test_df)\n",
    "result,output = model.predict(test_df['text'].values.tolist())\n",
    "acc, f1 = eval_metrics(test_df['labels'],result)\n",
    "print(acc,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7675b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7614727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
